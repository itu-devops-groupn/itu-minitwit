\newpage
\section{Lessons perspective}
\subsection{Refactoring code into .NET}
Refactoring the original Python Flask application to an ASP.NET Core application proved challenging. Initially, we scaffolded an entire Razor Page application\footnote{https://github.com/itu-devops-groupn/itu-minitwit/commit/deaa7d4d4cfa54782cb72cd7417c7f033fc5aac5}, but due to confusion about the course requirements, we scrapped it and pivoted to a minimal API approach\footnote{https://github.com/itu-devops-groupn/itu-minitwit/commit/b892da1d2f537e4c542e64fdcd49ad428b58e3b2}. This attempt to create a one-to-one copy of the single Python file resulted in complications due to the differences in the programming languages, including static versus dynamic typing and handling database connections and queries. In the end, we decided to import our Chirp application from the BDSA course due to time limits. The lesson learned is that refactoring to another language requires ample planning of the necessary frameworks and the architecture of the new application.

\subsection{Migrating from SQLite to PostgreSQL}
We faced challenges migrating from SQLite to PostgreSQL due to differences in the databases' queries. Initially, we attempted to use pgloader to convert our database into a PostgreSQL dump file and execute it on a test database, but this approach failed. Consequently, we created a SQLite dump file and manually converted it into a PostgreSQL dump file by adjusting specific queries that were incompatible between the two systems. We then used the PostgreSQL interactive terminal to execute the modified dump file into our database. Simultaneously, we deployed the latest application image to support PostgreSQL instead of SQLite, which was a minor change because we were already using EFCore in our infrastructure\footnote{https://github.com/itu-devops-groupn/itu-minitwit/commit/c721dfab96e5fd7ba91f71cdb948357a693a86c2}. 

\subsection{Implementing Docker Swarm}
When we initially attempted to implement Docker Swarm, we encountered issues with the firewall. We had not realized that specific ports needed to be allowed, which prevented the application from functioning correctly, as it could only be accessed through the workers' IP addresses. After identifying our mistake, we researched firewall settings, which made us more mindful of the ports we needed to open. This also resolved the issue with Docker Swarm.

\subsection{Implementing logging} \label{lessons:logging}
We attempted to implement logging throughout development using the Elasticsearch, Logstash, and Kibana (ELK) stack. However, we never got it fully operational for production use. Early on, we recognized the value of logging when our program crashed randomly after deployments. Without logs, we had to guess and apply quick fixes. Eventually, examining the Docker container logs revealed the crashes were due to deadlocks caused by high request loads. Understanding this allowed us to implement asynchronous methods to handle tasks better and prevent future deadlocks. \\

Initially, the setup seemed robust, and we had a functional local project within the first week of trying to implement logging. But transferring this to the MiniTwit-project proved problematic, with issues related to ports, networks, and authentications preventing proper read/write operations. We then discovered a setup script to configure the ELK stack, which resolved these issues theoretically.\footnote{https://github.com/itu-devops/itu-minitwit-logging/tree/new-elk-stack\cite{elk}} However, implementing this solution late in the process made us hesitant to integrate it into production, hence it remains in a separate branch.\footnote{https://github.com/itu-devops-groupn/itu-minitwit/tree/feature/setup-logging}

\subsection{Reflection on DevOps-workstyle}
The DevOps philosophy has required every developer in the group to be able to do "Operations" work. We have facilitated this through our CI/CD workflow. This differs from a lot of our earlier projects since they have not required deployment to a server and have usually only involved a single final build and hand-in. The only course that has required continuous deployment was BDSA from our 3rd semester and for that, we did do DevOps style deployment with automation. During the project, we focused on automating as much of the program as possible, as well as keeping it as "clean" as possible to use. Not having a proper test environment, in the beginning, slowed our development process down. Partly due to the public error tracking, we were overly cautious about making changes to our deployment process. A stable testing environment is crucial for smooth development cycles and fostering innovation. Without it, there's a risk of accepting solutions that work without optimizing them. \\

\label{lastpage}